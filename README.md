# Airline Tweet Sentiment Analysis

**ML Internship Take-Home Assignment**  
**Final Performance**: 74.38% weighted F1-score using SVM with RBF kernel

---

## ğŸš€ Quick Start

### View Key Results:
- **ğŸ“Š Complete Documentation**: `docs/README.md` - Organized visualizations and insights
- **ğŸ“ˆ Model Performance**: `docs/model_evaluation/` - Confusion matrices and performance metrics
- **ğŸ”¬ Methodology**: `docs/methodology/` - Process diagrams and experimental comparisons  
- **ğŸ“ˆ Data Analysis**: `docs/data_analysis/` - EDA visualizations
- **ğŸ“ Reflection**: `reflection.md` - Detailed analysis and lessons learned
- **ğŸ“‹ Complete Summary**: `ASSIGNMENT_SUMMARY.md` - Full assignment overview

### Run Final Evaluation:
```bash
python complete_evaluation.py
```

### Run Systematic Experiments:
```bash
cd experiments
python experiment_runner.py
```

### Run Optional Bonus Task:
```bash
cd experiments
python data_augmentation.py
```

### Run Enhanced Features Experiment:
```bash
cd experiments
python enhanced_features.py
```

**Results saved to**: 
- `experiments/results/data_augmentation_results.json`
- `experiments/results/enhanced_features_results.json`

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ ğŸ“ src/                    # Core implementation modules
â”œâ”€â”€ ğŸ“ experiments/            # Systematic experimentation framework  
â”‚   â”œâ”€â”€ experiment_runner.py   # Systematic model comparison
â”‚   â”œâ”€â”€ data_augmentation.py   # âœ… Optional bonus: synonym replacement
â”‚   â”œâ”€â”€ enhanced_features.py   # Feature engineering experiment
â”‚   â””â”€â”€ ...                    # Other experiments
â”œâ”€â”€ ğŸ“ docs/                   # ğŸ“Š Organized documentation & visualizations
â”‚   â”œâ”€â”€ README.md              # Complete documentation overview
â”‚   â”œâ”€â”€ model_evaluation/      # Final model performance & confusion matrices
â”‚   â”œâ”€â”€ methodology/           # Process diagrams & experimental comparisons
â”‚   â””â”€â”€ data_analysis/         # EDA visualizations & dataset insights
â”œâ”€â”€ ğŸ“ final_evaluation/       # Assignment deliverables (reports & metrics)
â”œâ”€â”€ ğŸ“ results/                # EDA outputs & analysis
â”œâ”€â”€ ğŸ“ data/                   # Tweet datasets  
â”œâ”€â”€ ğŸ“ embeddings/             # GloVe embeddings
â”œâ”€â”€ reflection.md              # âœ… Required reflection section
â”œâ”€â”€ complete_evaluation.py     # Final evaluation script
â””â”€â”€ ASSIGNMENT_SUMMARY.md      # Complete assignment overview
```

---

## ğŸ¯ Assignment Requirements Status

| Requirement | Status | Location |
|-------------|--------|----------|
| GloVe-based approach | âœ… Complete | `src/embeddings.py` |
| CPU-friendly models | âœ… Complete | SVM, Logistic Regression, etc. |
| Confusion matrix | âœ… Complete | `final_evaluation/confusion_matrix.png` |
| Misclassification analysis | âœ… Complete | See evaluation output |
| Reflection section | âœ… Complete | `reflection.md` |
| Systematic methodology | âœ… Complete | `experiments/` framework |
| **Optional bonus: Data augmentation** | âœ… **Complete** | `experiments/data_augmentation.py` |

---

## ğŸ“Š Key Results

### Systematic Experiment Results:
- **Experiments Conducted**: 10+ different model configurations
- **Performance Range**: 65.29% - 74.38% F1-score
- **Winner**: SVM with RBF kernel (74.38% F1)
- **Runner-up**: Logistic Regression with sum aggregation (73.94% F1)
- **Methodology**: Cross-validation, reproducible seeds, systematic comparison

### Final Model Performance:
- **Model**: SVM with RBF kernel
- **Weighted F1**: **74.38%** (excellent for CPU-friendly models)
- **Accuracy**: 73.57%
- **Training Time**: ~30 seconds on CPU

### Per-Class Performance:
- **Negative**: 81.88% F1 (strongest)
- **Positive**: 64.11% F1  
- **Neutral**: 60.01% F1 (most challenging due to class imbalance)

### Dataset:
- **Training**: 11,712 airline tweets
- **Testing**: 2,928 airline tweets  
- **Classes**: Negative (62.7%), Neutral (21.2%), Positive (16.1%)

---

## ğŸ¯ Visual Results Overview

### Systematic ML Methodology
![Methodology Flowchart](docs/methodology/methodology_flowchart.png)
*Complete workflow from data loading to error analysis with detailed process steps*

### Model Performance Comparison
![Experiment Comparison](docs/methodology/experiment_comparison.png)
*Performance comparison across 10+ model configurations and per-class results for best model*

### Final Model Evaluation
![Confusion Matrix](docs/model_evaluation/confusion_matrix_normalized.png)
*Normalized confusion matrix showing prediction accuracy percentages*

> ğŸ“‹ **See [docs/README.md](docs/README.md) for complete visualization gallery and detailed analysis**

---

## ğŸ”¬ Technical Highlights

### Systematic Approach:
- 10+ model configurations tested
- Cross-validation for reliable estimates
- Reproducible methodology with fixed seeds

### Engineering Excellence:
- Modular, maintainable architecture
- Comprehensive caching system
- Detailed logging and evaluation
- Feature engineering experiments (GloVe + handcrafted features)

### ML Best Practices:
- Class imbalance handling (`class_weight='balanced'`)
- Feature scaling for SVM optimization
- Comprehensive error analysis

---

## ğŸ“ˆ Performance Context

The **74.38% F1-score** places the model in the **"good performance"** category:

- Basic sentiment models: 60-65% F1
- **Good performance: 70-75% F1** â† This result
- State-of-the-art: 80-85% F1 (transformer models)

This represents excellent performance for CPU-friendly models within assignment constraints.


